{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSLATOR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backend_bases import RendererBase\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.fftpack import fft\n",
    "%matplotlib inline\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing import image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading files containing audio and the path where the image has to be stored \n",
    "audio_path = '..input/kan_audio_2'\n",
    "pict_Path = '..input/picturedata'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subFolderList = []\n",
    "for x in os.listdir(audio_path):\n",
    "    if os.path.isdir(audio_path + '/' + x):\n",
    "        subFolderList.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(pict_Path):\n",
    "    os.makedirs(pict_Path)\n",
    "subFolderList = []\n",
    "for x in os.listdir(audio_path):\n",
    "    if os.path.isdir(audio_path + '/' + x):\n",
    "        subFolderList.append(x)\n",
    "        if not os.path.exists(pict_Path + '/' + x):\n",
    "            os.makedirs(pict_Path +'/'+ x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_audio = []\n",
    "for i in subFolderList:\n",
    "    files=librosa.util.find_files(audio_path+\"/\"+i)\n",
    "    files=np.asarray(files)\n",
    "    for j in files:\n",
    "        data=librosa.util.find_files(j)\n",
    "        sample_audio.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting audio to spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, _, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# for each of the samples\n",
    "for i, filepath in enumerate(sample_audio[:9]):\n",
    "    # Make subplots\n",
    "    plt.subplot(3,3,i+1)\n",
    "    \n",
    "    # pull the labels\n",
    "    label = filepath.split('/')\n",
    "    plt.title(label)\n",
    "    \n",
    "    # create spectogram\n",
    "    samplerate, test_sound  = wavfile.read(filepath)\n",
    "    _, spectrogram = log_specgram(test_sound, samplerate)\n",
    "    \n",
    "    plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2img(wav_path, targetdir='', figsize=(4,4)):\n",
    "    fig = plt.figure(figsize=figsize)    \n",
    "    # use soundfile library to read in the wave files\n",
    "    samplerate, test_sound  = wavfile.read(filepath)\n",
    "    _, spectrogram = log_specgram(test_sound, samplerate)\n",
    "    \n",
    "    ## create output path\n",
    "    output_file = wav_path.split('/')[-1].split('.wav')[0]\n",
    "    output_file = targetdir +'/'+ output_file\n",
    "    #plt.imshow(spectrogram.T, aspect='auto', origin='lower')\n",
    "    plt.imsave('%s.jpg' % output_file, spectrogram)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get all the spectro image in one folder\n",
    "for i, x in enumerate(subFolderList[:10]):\n",
    "    print(i, ':', x)\n",
    "    all_files = [y for y in os.listdir(audio_path +'/'+ x) if '.wav' in y]\n",
    "    for file in all_files[:30]:\n",
    "        wav2img(audio_path + x + '/' + file, pict_Path +'/'+ x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a .csv containing the images and name of labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"..input/image_class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    img = image.load_img('..input/picturedata'+'/'+train['id'][i]+'.jpg')\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting train & test\n",
    "X = np.array(train_image)\n",
    "y = np.array(train.drop(['id', 'label'],axis=1))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining conv2d model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting model\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_file='..input/test_audio_file'\n",
    "image_file='..input/test_image'\n",
    "wav2img(voice_file,image_file)\n",
    "for i in os.listdir(image_file):\n",
    "    img=Image.open(image_file+\"/\"+i)\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.array(train.columns[2:])\n",
    "proba = model.predict(img.reshape(1,266,480,3))\n",
    "top3 = np.argsort(proba[0])[:-4:-1]\n",
    "for i in range(3):\n",
    "    print(\"{}\".format(classes[top_3[i]])+\" ({:.3})\".format(proba[0][top_3[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSLATOR ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "import string\n",
    "from pickle import load\n",
    "from pickle import dump\n",
    "from numpy.random import rand\n",
    "from numpy.random import shuffle\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dense\n",
    "from keras.utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras .models import load_model\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##defining functions##\n",
    "#loading document\n",
    "def load_doc(filename):\n",
    "    file = open(filename, mode='rt')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "# split a loaded document into sentences\n",
    "def to_pairs(doc):\n",
    "    lines = doc.strip().split('\\n')\n",
    "    pairs = [line.split('\\t') for line in  lines]\n",
    "    return pairs\n",
    "#preprocessing data\n",
    "def clean_pairs(lines):\n",
    "    cleaned = list()\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for pair in lines:\n",
    "        clean_pair = list()\n",
    "        for line in pair:\n",
    "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "            line = line.decode('UTF-8')\n",
    "            line = line.split()\n",
    "            line = [word.lower() for word in line]\n",
    "            line = [word.translate(table) for word in line]\n",
    "            line = [re_print.sub('', w) for w in line]\n",
    "            line = [word for word in line if word.isalpha()]\n",
    "            clean_pair.append(' '.join(line))\n",
    "        cleaned.append(clean_pair)\n",
    "    return array(cleaned)\n",
    "def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "    \n",
    "    \n",
    "    \n",
    "filename = \"..input/kan_eng.txt\"\n",
    "doc = load_doc(filename)\n",
    "pairs = to_pairs(doc)\n",
    "clean_pairs = clean_pairs(pairs)\n",
    "save_clean_data(clean_pairs,'kannada-english.pkl')\n",
    "\n",
    "for i in range ():\n",
    "    print('[%s] => [%s]' % (clean_pairs[i,0],clean_pairs[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    " def save_clean_data(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)\n",
    "    \n",
    "raw_dataset = load_clean_sentences('kannada-english.pkl')\n",
    "n_sentences = 1000\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "shuffle(dataset)\n",
    "#splitting data set\n",
    "train, test = dataset[:800], dataset[800:]\n",
    "save_clean_data(dataset, 'kannada-english-both.pkl')\n",
    "save_clean_data(train, 'kannada-english-train.pkl')\n",
    "save_clean_data(test, 'kannada-english-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_sentences(filename):\n",
    "    return load(open(filename, 'rb'))\n",
    "dataset = load_clean_sentences('kannada-english-both.pkl')\n",
    "train = load_clean_sentences('kannada-english-train.pkl')\n",
    "test = load_clean_sentences('kannada-english-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a tokenizer\n",
    "def create_tokenizer(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "def max_length(lines):\n",
    "    return max(len(line.split()) for line in lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare kannada tokenizer\n",
    "kan_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "kan_vocab_size = len(kan_tokenizer.word_index) + 1\n",
    "kan_length = max_length(dataset[:, 0])\n",
    "print('Kannada Vocabulary Size: %d' % kan_vocab_size)\n",
    "print('Kannada Max Length: %d' % (kan_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare english tokenizer\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 1])\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
    "print('English Max Length: %d' % (eng_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    X = tokenizer.texts_to_sequences(lines)\n",
    "    X = pad_sequences(X, maxlen=length, padding='post')\n",
    "    return X\n",
    "# one hot encode target sequence\n",
    "def encode_output(sequences, vocab_size):\n",
    "    ylist = list()\n",
    "    for sequence in sequences:\n",
    "        encoded = to_categorical(sequence, num_classes=vocab_size)\n",
    "        ylist.append(encoded)\n",
    "    y = array(ylist)\n",
    "    y = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = encode_sequences(kan_tokenizer, kan_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
    "trainY = encode_output(trainY, kan_vocab_size)\n",
    "testX = encode_sequences(kan_tokenizer, kan_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
    "testY = encode_output(testY, kan_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define model\n",
    "def define_model(src_vocab, tar_vocab, src_timesteps, tar_timesteps, n_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(src_vocab, n_units, input_length=src_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(n_units))\n",
    "    model.add(RepeatVector(tar_timesteps))\n",
    "    model.add(LSTM(n_units, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(tar_vocab, activation='softmax')))\n",
    "    return model\n",
    "model = define_model(eng_vocab_size, kan_vocab_size, eng_length, kan_length, 256)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "filename = '..input/kan_eng.txt'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "model.fit(trainX, trainY, epochs=30, batch_size=500, validation_data=(testX, testY), callbacks=[checkpoint], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map an integer to a word\n",
    "def word_for_id(integer, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == integer:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate target given source sequence\n",
    "def predict_sequence(model, tokenizer, source):\n",
    "    prediction = model.predict(source, verbose=0)[0]\n",
    "    integers = [argmax(vector) for vector in prediction]\n",
    "    target = list()\n",
    "    for i in integers:\n",
    "        word = word_for_id(i, tokenizer)\n",
    "        if word is None:\n",
    "            break\n",
    "        target.append(word)\n",
    "    return ' '.join(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, sources, raw_dataset):\n",
    "    actual, predicted = list(), list()\n",
    "    for i, source in enumerate(sources):\n",
    "        source = source.reshape((1, source.shape[0]))\n",
    "        translation = predict_sequence(model, kan_tokenizer, source)\n",
    "        raw_target, raw_src = raw_dataset[i]\n",
    "        if i < 10:\n",
    "            print('src=[%s], target=[%s], predicted=[%s]' % (raw_src, raw_target, translation))\n",
    "        actual.append([raw_target.split()])\n",
    "     #calculate BLEU score\n",
    "    predicted.append(translation.split())\n",
    "    print('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
    "    print('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
    "    print('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
    "    print('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ataset = load_clean_sentences('kannada-english-both.pkl')\n",
    "train = load_clean_sentences('kannada-english-train.pkl')\n",
    "test = load_clean_sentences('kannada-english-test.pkl')\n",
    "eng_tokenizer = create_tokenizer(dataset[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "eng_length = max_length(dataset[:, 0])\n",
    "kan_tokenizer = create_tokenizer(dataset[:, 1])\n",
    "kan_vocab_size = len(kan_tokenizer.word_index) + 1\n",
    "kan_length = max_length(dataset[:, 1])\n",
    "trainX = encode_sequences(kan_tokenizer, eng_length, train[:, 1])\n",
    "testX = encode_sequences(kan_tokenizer, eng_length, test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('..input/kan_eng.txt')\n",
    "print('train')\n",
    "evaluate_model(model, eng_tokenizer, trainX, train)\n",
    "print('test')\n",
    "evaluate_model(model, eng_tokenizer, testX, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
